{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BKeita-collab/PDM/blob/main/Assignment_PDM7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfUw5Z_PZxX"
      },
      "source": [
        "## Gradient Descent and Linear Regression with PyTorch\n",
        "\n",
        "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxHhq_NNPZxe"
      },
      "source": [
        "Before we begin, we need to install the required libraries. The installation of PyTorch may differ based on your operating system / cloud environment. You can find detailed installation instructions here: https://pytorch.org ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmxPl0scPZxf"
      },
      "source": [
        "## Introduction to Linear Regression\n",
        "\n",
        "First the foundational algorithms in machine learning: *Linear regression*. You will create a model that predicts crop yields for apples and oranges (*target variables*) by looking at the average temperature, rainfall, and humidity (*input variables or features*) in a region. Here's the training data:\n",
        "\n",
        "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
        "\n",
        "In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
        "\n",
        "```\n",
        "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity:\n",
        "\n",
        "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ehWWhlhPZxi"
      },
      "source": [
        "The *learning* part of linear regression is to figure out a set of weights `w11, w12,... w23, b1 & b2` using the training data, to make accurate predictions for new data. The _learned_ weights will be used to predict the yields for apples and oranges in a new region using the average temperature, rainfall, and humidity for that region. \n",
        "\n",
        "You will _train_ our model by adjusting the weights slightly many times to make better predictions, using an optimization technique called *gradient descent*. Let's begin by importing Numpy and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RswCKWtRPZxj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFADBKQmPZxp"
      },
      "source": [
        "## Training data\n",
        "\n",
        "You can represent the training data using two matrices: `inputs` and `targets`, each with one row per observation, and one column per variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8SasxPAyPZxq"
      },
      "outputs": [],
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "drh8rR6RPZxr"
      },
      "outputs": [],
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJhE-b4nPZxs"
      },
      "source": [
        "The input and target variables have been separated because you will operate on them separately.\n",
        "\n",
        "Let's convert the arrays to PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbQV4UapPZxt",
        "outputId": "20443d79-61c3-4f7e-933a-2b4400348022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "# Convert inputs and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs.shape)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAaGA_mAPZxu"
      },
      "source": [
        "## Linear regression model from scratch\n",
        "\n",
        "The weights and biases (`w11, w12,... w23, b1 & b2`) can also be represented as matrices, initialized as random values. The first row of `w` and the first element of `b` are used to predict the first target variable, i.e., yield of apples, and similarly, the second for oranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD1FpDUtPZxu",
        "outputId": "7364a233-114d-45fa-b871-6f6246f2a1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7384, -0.8493, -0.8118],\n",
            "        [ 1.8652,  0.2408, -1.9276]], requires_grad=True)\n",
            "tensor([ 0.1275, -0.7642], grad_fn=<PermuteBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzK3AIjrPZxv"
      },
      "source": [
        "`torch.randn` creates a tensor with the given shape, with elements picked randomly from a [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) with mean 0 and standard deviation 1.\n",
        "\n",
        "Our *model* is simply a function that performs a matrix multiplication of the `inputs` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
        "\n",
        "![matrix-mult](https://i.imgur.com/WGXLFvA.png)\n",
        "\n",
        "We can define the model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tAqir7JwPZxy"
      },
      "outputs": [],
      "source": [
        "# torch.reshape(x @ w.t() + b, (-1,1))\n",
        "def model(x):\n",
        "    return x @ w.T + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjpHxzLEPZxz"
      },
      "source": [
        "## Train the model using gradient descent\n",
        "\n",
        "As seen above, we reduce the loss and improve our model using the gradient descent optimization algorithm. Thus, we can _train_ the model using the following steps:\n",
        "\n",
        "1. Generate predictions\n",
        "\n",
        "2. Calculate the loss\n",
        "\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "\n",
        "5. Reset the gradients to zero\n",
        "\n",
        "Let's implement the above step by step."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('size of input = {}, w = {} and b = {}'.format(inputs.shape, w.shape, b.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Ct9-vfSbEg",
        "outputId": "15836bda-fe81-4259-b713-e418d65056b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of input = torch.Size([5, 3]), w = torch.Size([2, 3]) and b = torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xIKoXPGxPZx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87646447-89ee-4cab-d0e4-933b5ca4844c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-145.5931,   68.6492],\n",
            "        [-193.7695,   66.8022],\n",
            "        [-225.0146,   81.9852],\n",
            "        [-141.7527,  128.5263],\n",
            "        [-189.1894,   16.1284]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OGZ0-wvPZx1",
        "outputId": "ca62b815-bf1d-45c2-c20a-46fac2df5cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36940.7148, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the loss\n",
        "def mse(preds, targets):\n",
        "    error = preds - targets\n",
        "    mse = torch.sum(error ** 2) / error.numel()\n",
        "    return mse\n",
        "\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp5rbEC-PZx1"
      },
      "source": [
        "## Train for multiple epochs\n",
        "\n",
        "To reduce the loss further, we can repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an _epoch_. Let's train the model for 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zOEXEAE_PZx3"
      },
      "outputs": [],
      "source": [
        "# Train for 100 epochs\n",
        "learning_rate = 1e-5\n",
        "\n",
        "for i in range(100):\n",
        "    # compute the prediction\n",
        "    preds = model(inputs)\n",
        "    # compute the loss\n",
        "    loss = mse(preds, targets)\n",
        "    # What does the following line do ?\n",
        "    loss.backward()\n",
        "    # what to do next\n",
        "    with torch.no_grad():\n",
        "      w -= w.grad * learning_rate\n",
        "      b -= b.grad * learning_rate\n",
        "      w.grad.zero_()\n",
        "      b.grad.zero_()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kSmnNfBPZx5"
      },
      "source": [
        "Once again, let's verify that the loss is now lower:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uXAs8HiPZx6",
        "outputId": "a51577e6-7389-47b9-e231-9bb1361ee74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(851.0043, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Calculate loss\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7YmP-XPZx-"
      },
      "source": [
        "The loss is now much lower than its initial value. Let's look at the model's predictions and compare them with the targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW4yfDxNPZx_",
        "outputId": "f8d48e45-16ef-4f5a-e63e-22bfe9d1313a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 61.7426,  81.5097],\n",
              "        [ 81.0986,  90.1357],\n",
              "        [113.8552, 138.9080],\n",
              "        [ 47.1276, 101.0369],\n",
              "        [ 84.8203,  63.2995]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Predictions\n",
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvcFOWoxPZyA",
        "outputId": "fefa0092-d817-463e-c43b-1769d5fd480f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Targets\n",
        "targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQOouyrGPZyC"
      },
      "source": [
        "The predictions are now quite close to the target variables. We can get even better results by training for a few more epochs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Wiv8nrPZyC"
      },
      "source": [
        "## How would you do with the pytorch build in functions ?\n",
        "\n",
        "Hint: use the nn.Linear function and mse_loss function of pytorch\n",
        "\n",
        "Hint2: don't forgte the Tensordataset and the dataloader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z5FskhIWPZyG"
      },
      "outputs": [],
      "source": [
        "# Utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    \n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb,yb in train_dl:\n",
        "            \n",
        "            # 1. Generate predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # 3. Compute gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reset the gradients to zero\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDA0dFLBPZyG"
      },
      "source": [
        "Some things to note above:\n",
        "\n",
        "* We use the data loader defined earlier to get batches of data for every iteration.\n",
        "\n",
        "* Instead of updating parameters (weights and biases) manually, we use `opt.step` to perform the update and `opt.zero_grad` to reset the gradients to zero.\n",
        "\n",
        "* We've also added a log statement that prints the loss from the last batch of data for every 10th epoch to track training progress. `loss.item` returns the actual value stored in the loss tensor.\n",
        "\n",
        "Let's train the model for 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F \n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "trNdHZ-hakof"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creation of training and test dataset \n",
        "batch_size = 5\n",
        "train_ds = torch.utils.data.TensorDataset(inputs, targets)\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "5ixf4WB3aLND"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = F.mse_loss\n",
        "model = nn.Linear(3, 2)\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "I2Q-2x8VY4L5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usVmuBndPZyH",
        "outputId": "23e4ed7f-5ca4-4406-8d4a-f5160438e77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 850.6973\n",
            "Epoch [20/100], Loss: 603.5648\n",
            "Epoch [30/100], Loss: 531.2391\n",
            "Epoch [40/100], Loss: 470.3055\n",
            "Epoch [50/100], Loss: 416.6523\n",
            "Epoch [60/100], Loss: 369.3583\n",
            "Epoch [70/100], Loss: 327.6643\n",
            "Epoch [80/100], Loss: 290.9031\n",
            "Epoch [90/100], Loss: 258.4865\n",
            "Epoch [100/100], Loss: 229.8971\n"
          ]
        }
      ],
      "source": [
        "fit(100, model, loss_fn, opt, train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox7T1jJOPZyK"
      },
      "source": [
        "Let's generate predictions using our model and verify that they're close to our targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X5w9pzZPZyL",
        "outputId": "38bd6747-ebbf-4d66-8665-50908ee45533"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 62.4071,  74.7856],\n",
              "        [ 83.5678,  99.8720],\n",
              "        [107.1723, 127.5762],\n",
              "        [ 50.8556,  62.9362],\n",
              "        [ 87.0088, 102.5644]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z59AVibZPZyM",
        "outputId": "6b5199fa-cd1b-412f-870c-77984aeb5ea4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Compare with targets\n",
        "targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkyM6r2IPZyM"
      },
      "source": [
        "Indeed, the predictions are quite close to our targets. We have a trained a reasonably good model to predict crop yields for apples and oranges by looking at the average temperature, rainfall, and humidity in a region. We can use it to make predictions of crop yields for new regions by passing a batch containing a single row of input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNBP0AkRPZyN",
        "outputId": "fb4e9701-afea-40a6-ba87-0bbb296fc9a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[60.7363, 72.8951]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model(torch.tensor([[75, 63, 44.]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0X9mJbsPZyN"
      },
      "source": [
        "Comment the results... Which amount of orange and apples does it predict ?\n",
        "60 apples and 72 orange"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Assignment-PDM7-2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}